在中国AIGC产业峰会的现场，20位大咖展开激辩。从软件应用、智能终端乃至具身智能等，AIGC正在全面席卷，「你好，新应用！」成为本届AIGC峰会主题。来自AIGC底层基础设施、模型层、应用层的企业玩家，以及来自市场学术界的洞察者，畅谈大模型落地元年这个万亿市场的的机遇与挑战。现场乌泱泱一片，500人的会场可以说是座无虚席（其实站也要没有席了）。线上也有数百万网友围观并积极讨论，以及数十家行业知名媒体参与了大会的直播跟报道，全网总曝光量超千万。为了让更多读者更全面、系统地了解本次AIGC峰会的内容，深入感知这股时代浪潮的发展，量子位联合各大模型做了万字梳理，希望能为大家提供一份有价值的行业参考。（建议收藏再食用）本次梳理主要围绕五个方面展开，分别是AIGC的模型层、应用层、基础设施层的参与者，以及行业洞察者的观点，最后是圆桌讨论的精彩观点。AIGC模型层：微软阿里高通等玩家谈落地微软李冕：AI应用已进入新阶段，微软助力企业级应用全球落地微软大中华区Azure云事业部总经理李冕分享了微软Copilot与Azure AI平台如何助力企业级应用的全球落地。李冕认为，过去12个月AI经历了数次迭代，现在AI应用已进入到一个新的阶段。企业如何打造自己的应用？怎么实现AI带来的真正价值？可以从四个方面来考虑应用落地：提升员工生产力，重塑与用户的互动关系，重塑企业内部流，加强产品和服务。他强调了在企业打造自己的应用时微软可以为企业提供的一系列支持。AI模型层面，李冕展开介绍了Azure平台支持的三类模型，分别是OpenAI系列模型、第三方开源模型和企业自研模型（BYOM）。同时，也讲述了小模型（SLM）在特定场景下的应用前景。对于开发工具，李冕提到Azure提供低代码、无代码的Microsoft Copilot Studio工作台以及针对深度定制的Azure AI Studio，方便企业快速开发AI应用。考虑到企业级应用需求，李冕还表示微软不仅在最上面的模型层为企业提供支持，还提供下面的调度层、硬件层、云数据中心等的一系列配套服务。李冕在演讲最后重申了微软在数据隐私安全方面的承诺：“客户的数据就是客户的数据，客户的数据不会被用来训练其它模型，所有客户数据均有企业级防护，受到全面的企业合规和安全控制的保护。”昆仑万维方汉：天工SkyMusic音乐大模型将大大降低音乐创作的门槛和成本昆仑万维董事长兼CEO方汉分享了“天工多模态大模型的演进落地”。大会当天，昆仑万维发布了「天工3.0」，这是中国音乐AIGC领域首个实现SOTA水平的模型。同时，他还宣布「天工3.0」基座大模型与「天工SkyMusic」音乐大模型正式开启公测。「天工3.0」拥有4000亿参数，超越了3140亿参数的Grok-1，是全球最大的开源MoE大模型。在MMbench和MMbench-CN测试集上，「天工3.0」性能指标全面超越GPT-4V。通过专项的Agent训练，目前大模型可以做到“能搜能写能读能聊能说能画能听能唱”，应对多种复杂的内容创作需求。例如，它可以准确识别“成都迪士尼”是个梗，并给出游玩攻略；可以自动总结文献，生成大纲、PPT和脑图；还可以通过非代码方式生成智能体。方汉特别介绍了「天工SkyMusic」音乐大模型，得益于2000万首音乐的训练数据和独特的模型架构，「天工SkyMusic」在人声识别度、音质等方面已经超越Sora。「天工SkyMusic」支持根据音源和歌手特点生成音乐，并支持多种方言合成，大大降低了音乐创作的门槛和成本——各行各业使用的歌曲都能通过AI生成，成本迅速从几万块钱降到几分钱。最后，方汉分享了昆仑万维的愿景：“实现通用人工智能，让每个人更好地塑造和表达自我。”他认为，大模型的演进终将实现AGI，而AIGC能力普及则有助于打破强势文化的垄断，实现文化平权。作为一家全球化互联网企业，昆仑万维希望用AI技术为全球用户赋能。阿里通义千问林俊旸：智能模型应融入对视觉/语音的理解阿里通义千问开源负责人林俊旸，在现场分享了阿里通义千问大模型为“走向通用大模型”做出的努力。林俊旸表示，自开源以来，通义千问Qwen（为了更方便英文发音，对“千问”的音译）系列模型受到了国内外开发者的广泛关注。从去年8月开始，通义千问Qwen系列模型陆续开源上新。从7B、14B参数规模大小开始，直到开源了72B参数版本；最新动作，阿里通义千问家族还有一名“小成员”，是14B参数的MoE模型。而开发者社区的迫切需求，促使阿里快速开源了32B模型——这个模型的表现与72B参数模型表现接近，并且在某些方面相比，比MoE模型还具有优势。林俊旸在现场强调，阿里通义千问同时十分专注打造大模型使用生态。首先，通义千问的代码已经官方融入了抱抱脸的代码库，开发者可以更方便地使用通义千问的模型。其次，通义千问在第三方框架支持方面有不少进展，包括ollama在内的平台，都能一键使用Qwen系列模型。多语言、长序列、Post-training、Agent、多模态等能力相关问题，林俊旸也在现场做了分享。多语言：通义千问模型本质上是多语言的，而非仅仅是中英双语的；并且，团队在多语言能力上进行了检测和优化。长序列：Qwen系列模型一直没有卷长文本，这件事并不好做，不仅要保证“长”，同时要保证效果；目前32k版本表现已经比较稳定；大海捞针等评估发现长序列可以在Chatbot上落地实用功能。Post-training：通过SAT等在数据等方面，优化post-training，让大模型的潜力爆发。Agent：实现方式（之一）是做更多数据标注、研究to use agent相关。多模态（Qwen-VL）：非常智能的模型应该融入对视觉、语音方面的理解，今年会重点关注视频模态的研究，思考如何打造一个VL-Agent。
高通万卫星：具有异构计算系统的高通AI引擎可以充分满足生成式AI的多样性要求
高通公司AI产品技术中国区负责人万卫星在演讲中表示，作为芯片厂商，高通正通过提供领先的产品和解决方案，推动AIGC相关产业的规模化扩展。他指出，高通认为终端侧生成式AI的时代已经到来。高通在去年10月发布的第三代骁龙8和骁龙X Elite两款产品中，已经将大语言模型完整搬到了端侧，赋能了众多AI手机和AI PC。多模态趋势下，今年2月，高通也把多模态大模型完整地搬移到端侧。在发布的骁龙X Elite这款产品上，高通也演示了全球首个在Windows PC上运行的音频推理多模态大模型。万卫星表示，不同领域的生成式AI用例具有多样化的要求，背后所需的AI模型也是千差万别，很难有一种处理器可以完美适用所有用例。在这方面，高通推出了具有异构计算系统的高通AI引擎，包含多种处理器组件，可以充分满足生成式AI的多样性要求。其中重点讲了NPU。基于用户需求和终端用例的多年演进，高通NPU不断升级。第三代骁龙8的Hexagon NPU还集成了专门为生成式AI打造的Transformer加速模块，以及微架构升级、独立供电轨道、微切片推理等先进AI技术。万卫星还透露高通今年会重点支持多模态模型端侧化，以及支持更高参数量大语言模型在端侧的部署。说完硬件设计，万卫星介绍了高通的重要AI软件产品，包括跨平台、跨终端的统一解决方案高通AI软件栈（Qualcomm AI Stack）。
你只需要在高通一个平台上完成模型的优化部署工作，可以非常方便的把这部分工作迁移到其它高通产品线。
此外，高通还在今年的MWC巴塞罗那发布了高通AI Hub（Qualcomm AI Hub）。该产品面向第三方开发者和合作伙伴，可以帮助开发者更加充分的利用高通和骁龙底层芯片的硬件算力，开发出自己的创新AI应用。最后他总结了高通在AI方面的优势，在于“无与伦比的硬件设计、顶尖的异构计算能力、可扩展的AI软件工具以及广泛的生态系统和模型支持”。蚂蚁李建国：超70%代码问题单纯靠基座模型是解决不了的
超70%的问题需要端到端代码生成能力解决，目前单纯靠基座模型还远远不能满足。
在中国AIGC产业峰会上，蚂蚁代码大模型CodeFuse负责人李建国这样说道，他还指出，当前代码大模型虽然在基座模型和应用产品上演进飞速，但要在企业中真正实现研发效率的大幅提升，仍面临诸多挑战。从软件研发全生命周期来看，从最初的需求设计到编码开发、测试构建、发布运维、数据洞察等环节，写代码可能只占1/5甚至更少的工作量。李建国表示，蚂蚁集团希望打造一个“研发智能体”，通过智能Agents实现任务分发与衔接，将各环节连接起来，全面提升研发效能。CodeFuse刚发布时，就明确提出“要做全生命周期的代码大模型”。CodeFuse目前已开源13个仓库，覆盖代码训练、测试、DevOps运维、程序分析、评测等8大软件开发领域。李建国表示，这是全方位的开源。最后再来看整个领域，结合外部统计与蚂蚁实践，基座模型在实际运用过程中只能解决大约30%的问题，剩下70%的问题还需要端到端代码生成能力。除此之外，在Agent推理能力、需求需求拆解、跨模态交互等方面还需要持续演进。李建国还重点提到，垂直场景中，比如金融场景，生成代码的安全、可信、可靠的要求，这也是蚂蚁正在重点攻克的难题。虽然挑战不少、道阻且长，但李建国认为，蚂蚁将携手开源社区一起努力，在万物摩尔定律的牵引下，未来两三年可以一定程度解决这个问题。